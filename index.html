<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />

<style>
body {
    margin: 10px;
    padding: 10px;
/*     border: 1px solid #cccccc; */
    max-width: 1200px; /* Optional: Set a max-width for the content */
    margin-left: auto;
    margin-right: auto;
    background-color: #f9f9f9; /* Optional: Change the background color */
}
</style>
<title>Da Chang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Da Chang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="img/me.jpg" alt="alt text" width="180px" height="240px" />&nbsp;</td>
<td align="left">
<p style="line-height: 1.8;">Da Chang (昌达) <br />
Ph.D student,<br />
Pengcheng Laboratory,Shenzhen,China <br />
Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China</p>
<p>
<a href="changda24@mails.ucas.ac.cn">[Email]</a> 
<a href="https://scholar.google.com.hk/citations?user=glTBszIAAAAJ&hl=zh-CN">[Google Scholar]</a> 
<a href="https://www.linkedin.com/in/da-chang-4a13262b8/">[Linkedin]</a> 
<a href="https://github.com/VceChang">[Github]</a> 

</p>
</td></tr></table>
<h2>About me</h2>
<p style="line-height: 1.8;">
I graduated from the Department of Intelligent Science and Technology, <a href="https://soa.csu.edu.cn/">School of Automation</a> ,<a href="https://www.csu.edu.cn/"> Central South University</a>.<br/>
Currently, I am a jointly educated PhD candidate in a collaborative program between the Shenzhen Institute of Advanced Technology,Chinese Academy of Sciences (<a href="https://www.siat.ac.cn/">SIAT</a>) and Pengcheng Laboratory(<a href="https://www.pcl.ac.cn/">PCL</a>).<br/> 
	
My research interests focus on deep learning optimization and generalization and the application of deep models to various domains. <br/>
I am very interested in the theory and application of deep learning. I would like to communicate with you about training techniques, application scenarios and optimization theories of deep learning.
 
</p>

<h2>News</h2>

<ul><li><p>[09/2024] - I will start my first year of doctoral study in Chinese Academy of Sciences</p></li></ul>
<ul><li><p>[06/2024] - I graduated from the School of Automation of Central South University.</p></li></ul>
<ul><li><p>[06/2024] - I won the outstanding undergraduate thesis of Central South University.</p></li></ul>

<h2>Research that I lead </h2>
<!-- <img src="img/me.jpg" alt="alt text" width="180px" height="240px" />&nbsp;</td>
<p><a href="https://arxiv.org/abs/2404.12734">DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer</a> <br />
<b>Da Chang</b>, Yu Li <br />
</p> -->

<table style="width: 100%; border-collapse: collapse;border: none;">
    <tr>
        <td style="width: 35%;text-align: center; vertical-align: middle; padding-right: 20px;border: none;">
            <img src="img/DLoRA.png" alt="DLoRA" style="max-width: 80%; height: auto;">
        </td>
         
        <td style="width: 65%; vertical-align: top;text-align: left;border: none;">
           <h3 style="line-height: 1.5;">DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer</h3>
	   <p style="line-height: 1.5;">
		<b>Da Chang</b>, Yu Li <br />
           	Preprint , 2024.4 <br />
	    <p>
            <p style="line-height: 1.8;">We explored the optimization of various full-parameter fine-tuning methods, such as LoRA in LLM. For OCR, a visual-text hybrid model, corresponding to the Transformer architecture, DoRA and LoRA have great improvements for visual encoders and text decoders in hybrid datasets including handwriting, print and Street View datasets, respectively.</p>
            <p><a href="https://arxiv.org/abs/2404.12734">paper</a>,<a href="https://github.com/VceChang/DLoRA-TrOCR">code</a></p>
        </td>
    </tr>
</table>

	
<h2>Research that I proudly participate in</h2>
<!-- <p>SfMDiffusion: Self-Supervised Monocular Depth Estimation in Endoscopy Based on Diffusion Models <br />
Yu Li, <b>Da Chang</b>, Jin Huang, Lan Dong, Du Wang, Liye Mei, Cheng Lei <br />
Under Review</p> -->

<table style="width: 100%; border-collapse: collapse;border: none;">
    <tr>
        <td style="width: 35%; text-align: center; vertical-align: middle; padding-right: 20px;border: none;">
            <img src="img/SfMD.jpg" alt="SfMD" style="max-width: 80%; height: auto;">
        </td>
         
        <td style="width: 65%; vertical-align: top;text-align: left;border: none;">
           <h3 style="line-height: 1.5;">SfMDiffusion: Self-Supervised Monocular Depth Estimation in Endoscopy Based on Diffusion Models</h3>
	   <p style="line-height: 1.5;">
		   Yu Li, <b>Da Chang</b>, Jin Huang, Lan Dong, Du Wang, Liye Mei, Cheng Lei <br />
		   Under Review , 2024.6 <br />
	   </p>
            <p style="line-height: 1.8;">For endoscope medical scenarios, we use the diffusion model for depth estimation. We build a teacher model, set knowledge distillation, optical appearance and ddim losses, and introduce the teacher's discriminative prior, which significantly enhances the accuracy and confidence of the results.</p>
            <a href="https://github.com/Skylanding/SfM-Diffusion">code</a></p>
        </td>
    </tr>
</table>

<table style="width: 100%; border-collapse: collapse;border: none;">
    <tr>
        <td style="width: 35%; text-align: center; vertical-align: middle; padding-right: 20px;border: none;">
            <img src="img/ttjm.png" alt="ttjm" style="max-width: 80%; height: auto;">
        </td>
         
        <td style="width: 65%; vertical-align: top;text-align: left;border: none;">
           <h3 style="line-height: 1.5;">Research on National Image Based on Social Sentiment Analysis of Modern International Events</h3>
	   <p style="line-height: 1.5;">
		   Xuechi Chen, Haifeng Lin, <b>Da Chang</b> <br />
		   Third prize of the 9th National Statistical Modeling Competition for College Students , 2023.8 <br />
	   </p>
            <p style="line-height: 1.8;">We selected the texts on the theme of "Beijing Winter Olympics" from the domestic Weibo social platform and the overseas Twitter social platform. Based on the fine-tuned BERT word segmentation and sentiment analysis to mine the latent detail tags of the text, and using the topic modeling method to determine the consistent topic, thereby constructing the national image visualization model and conducting qualitative analysis. </p>
        </td>
    </tr>
</table>



<h2>Honors and Awards </h2>
<ul><li><p>Second prize of the 8th National Biomedical Engineering Innovation Design Competition for College Students, China, 2023.</p></li></ul>
<ul><li><p>Third prize of the 9th National Statistical Modeling Competition for College Students, China, 2023.</p></li></ul>
<ul><li><p>Second Class Scholarship, CSU (Top 15%), 2023.</p></li></ul>
<ul><li><p>"ShanHe Excellent Student" Second Class Scholarship, CSU(Top 5%), 2022.</p></li></ul>
<ul><li><p>First-Class Scholarship, CSU (Top 5%), 2022.</p></li></ul>


<h2>Skills </h2>
<ul><li><p>Languages: Python, C/C++, MATLAB, LaTex.</p></li></ul>
<ul><li><p>Tools : PyTorch, Sklearn, AutoML Framework.</p></li></ul>	
	
</td>
</tr>
</table>
</body>
</html>
